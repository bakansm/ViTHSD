{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["VfGdCIXpjU-U","FnUz7coWkPRy","HIdSiF-20XCz","itWzjx6zWcGA","VfiJ4zdwHdkI"],"mount_file_id":"1NA0VR228f6-9bnFuBIp_cEr2yS67qYuz","authorship_tag":"ABX9TyOIgpwUtv1QjJJrHogSl4xV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Library "],"metadata":{"id":"VfGdCIXpjU-U"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2X6kFcCC4lS","executionInfo":{"status":"ok","timestamp":1680171675765,"user_tz":-420,"elapsed":5740,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"4f999ec1-36ea-45c3-dc52-e5e0e214e367"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"]}],"source":["pip install transformers"]},{"cell_type":"code","source":["pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Rv2mQWg4qSp","executionInfo":{"status":"ok","timestamp":1680171678947,"user_tz":-420,"elapsed":3188,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"b78ed840-10fe-4100-d479-3c10d7763ce0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"]}]},{"cell_type":"code","source":["pip install vncorenlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FApBCyT1EE_u","executionInfo":{"status":"ok","timestamp":1680171683845,"user_tz":-420,"elapsed":4903,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"76544f71-e86a-4569-c4de-589747ad13a3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: vncorenlp in /usr/local/lib/python3.9/dist-packages (1.0.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from vncorenlp) (2.27.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->vncorenlp) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->vncorenlp) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->vncorenlp) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->vncorenlp) (1.26.15)\n"]}]},{"cell_type":"code","source":["!mkdir -p vncorenlp/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/\n","\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n","\n","\n","!mkdir -p vncorenlp/models/postagger\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger \n","!mv vi-tagger vncorenlp/models/postagger/\n","\n","\n","!mkdir -p vncorenlp/models/ner\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz \n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n","!mv vi-500brownclusters.xz vncorenlp/models/ner/\n","!mv vi-ner.xz vncorenlp/models/ner/\n","!mv vi-pretrainedembeddings.xz vncorenlp/models/ner/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bWdFeu7rEBNk","executionInfo":{"status":"ok","timestamp":1680171691122,"user_tz":-420,"elapsed":7286,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"f5ae4cf8-6eb3-47a4-9826-71e4168d8919"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-30 10:21:22--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27412575 (26M) [application/octet-stream]\n","Saving to: ‘VnCoreNLP-1.1.1.jar’\n","\n","VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  --.-KB/s    in 0.09s   \n","\n","2023-03-30 10:21:23 (280 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n","\n","--2023-03-30 10:21:23--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 526544 (514K) [application/octet-stream]\n","Saving to: ‘vi-vocab’\n","\n","vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.004s  \n","\n","2023-03-30 10:21:23 (114 MB/s) - ‘vi-vocab’ saved [526544/526544]\n","\n","--2023-03-30 10:21:23--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 128508 (125K) [text/plain]\n","Saving to: ‘wordsegmenter.rdr’\n","\n","wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.002s  \n","\n","2023-03-30 10:21:23 (53.9 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n","\n","--2023-03-30 10:21:24--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29709468 (28M) [application/octet-stream]\n","Saving to: ‘vi-tagger’\n","\n","vi-tagger           100%[===================>]  28.33M  --.-KB/s    in 0.1s    \n","\n","2023-03-30 10:21:24 (266 MB/s) - ‘vi-tagger’ saved [29709468/29709468]\n","\n","--2023-03-30 10:21:25--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5599844 (5.3M) [application/octet-stream]\n","Saving to: ‘vi-500brownclusters.xz’\n","\n","vi-500brownclusters 100%[===================>]   5.34M  --.-KB/s    in 0.02s   \n","\n","2023-03-30 10:21:25 (304 MB/s) - ‘vi-500brownclusters.xz’ saved [5599844/5599844]\n","\n","--2023-03-30 10:21:25--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9956876 (9.5M) [application/octet-stream]\n","Saving to: ‘vi-ner.xz’\n","\n","vi-ner.xz           100%[===================>]   9.50M  --.-KB/s    in 0.03s   \n","\n","2023-03-30 10:21:26 (284 MB/s) - ‘vi-ner.xz’ saved [9956876/9956876]\n","\n","--2023-03-30 10:21:26--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 57313672 (55M) [application/octet-stream]\n","Saving to: ‘vi-pretrainedembeddings.xz’\n","\n","vi-pretrainedembedd 100%[===================>]  54.66M  --.-KB/s    in 0.1s    \n","\n","2023-03-30 10:21:29 (443 MB/s) - ‘vi-pretrainedembeddings.xz’ saved [57313672/57313672]\n","\n"]}]},{"cell_type":"markdown","source":["# Hyper parameters"],"metadata":{"id":"FnUz7coWkPRy"}},{"cell_type":"code","source":["max_len = 50\n","use_tokenizer = False\n","MODEL = 'xlm-roberta-base'"],"metadata":{"id":"sMbNuHXmU45D","executionInfo":{"status":"ok","timestamp":1680171691123,"user_tz":-420,"elapsed":10,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HIdSiF-20XCz"},"source":["# Read data"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"P49FSZZUqIQ2","executionInfo":{"status":"ok","timestamp":1680171691123,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"outputs":[],"source":["train_dataset = 'drive/MyDrive/CODE/ViTHSD/dataset/train.xlsx'\n","dev_dataset = 'drive/MyDrive/CODE/ViTHSD/dataset/dev.xlsx'\n","test_dataset = 'drive/MyDrive/CODE/ViTHSD/dataset/test.xlsx'"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"pksSFBGM0oQl","executionInfo":{"status":"ok","timestamp":1680171691124,"user_tz":-420,"elapsed":10,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"outputs":[],"source":["import pandas as pd\n","\n","train = pd.read_csv(train_dataset)\n","dev = pd.read_csv(dev_dataset)\n","test = pd.read_csv(test_dataset)"]},{"cell_type":"code","source":["len(train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgJI4DqAnotI","executionInfo":{"status":"ok","timestamp":1680171691124,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"6396d1a0-0f54-4afe-a24c-43fa768e0b9c"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7000"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["len(dev)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zb3MJ3wwfJCS","executionInfo":{"status":"ok","timestamp":1680171691124,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"b7406fef-39d6-417b-ee8b-48fae9b1284f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1201"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["len(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQXYVMxIfKvX","executionInfo":{"status":"ok","timestamp":1680171691124,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"812baa76-51b4-454d-9789-0629c6100e2c"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1800"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# EVAL metrics"],"metadata":{"id":"itWzjx6zWcGA"}},{"cell_type":"code","source":["def precision(pred, y):\n","    sum = 0\n","    for i in range(0, len(pred)):\n","        if y[i] == pred[i] and pred[i] != 0:\n","            sum = sum + 1 \n","\n","    pred = [i for i in pred if i != 0]\n","\n","    return sum / len(pred) if len(pred) > 0 else 0\n","\n","def recall(pred, y):\n","    sum = 0\n","    for i in range(0, len(pred)):\n","        if y[i] == pred[i] and pred[i] != 0:\n","            sum = sum + 1\n","\n","    y = [i for i in y if i != 0]\n","\n","    return sum / len(y) if len(y) > 0 else 0\n","\n","def f1(pred, y):\n","    p = precision(pred, y)\n","    r = recall(pred, y)\n","    return 2*p*r / (p+r) if (p+r) != 0 else 0\n","\n","def precision_score(preds, y):\n","    result = 0\n","    for i in range(0, len(preds)):\n","        result += precision(preds[i], y[i])\n","    return result / len(preds)\n","\n","def recall_score(preds, y):\n","    result = 0\n","    for i in range(0, len(preds)):\n","        result += recall(preds[i], y[i])\n","    return result / len(preds)   \n","\n","def f1_score(preds, y):\n","    return 2*precision_score(preds, y)*recall_score(preds, y) / (precision_score(preds, y)+recall_score(preds, y))"],"metadata":{"id":"LPkV1TqQWdKM","executionInfo":{"status":"ok","timestamp":1680171691124,"user_tz":-420,"elapsed":7,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["a = [2, 1, 0, 2, 1]\n","b = [2, 2, 0, 2, 1]\n","\n","f1(a, b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7WAf1aldEXZ","executionInfo":{"status":"ok","timestamp":1680171691125,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"d1f5c8f8-d9b7-4d0b-f8af-e05329ef96d7"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.75"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Feature extraction"],"metadata":{"id":"VfiJ4zdwHdkI"}},{"cell_type":"code","source":["from vncorenlp import VnCoreNLP\n","vncorenlp = VnCoreNLP(\"vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\") \n","\n","def tokennize_vn(text):\n","    sentences = vncorenlp.tokenize(text)\n","    s = ''\n","    for t in sentences:\n","        s = s + ' '.join(t) + ' '\n","    return s"],"metadata":{"id":"reIyzdb74Rgf","executionInfo":{"status":"ok","timestamp":1680171697682,"user_tz":-420,"elapsed":6564,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from keras.utils import to_categorical\n","import numpy as np\n","\n","def make_data(data):\n","    content = [str(d) for d in data['content']]\n","    if use_tokenizer:\n","        content = [tokennize_vn(str(d)) for d in data['content']]\n","    # else:\n","    #     content = data['content'].values\n","    label = data.iloc[:,2:].values\n","    label_to_categorical = []\n","    for d in label:\n","        lb = []\n","        for i in d:\n","            t = np.zeros(4, dtype=int)\n","            t[i] = 1\n","            lb.append(t.tolist())\n","        label_to_categorical.append(lb)\n","\n","    return content, label, label_to_categorical"],"metadata":{"id":"WsLYcHsUGoKJ","executionInfo":{"status":"ok","timestamp":1680171702701,"user_tz":-420,"elapsed":5024,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train_text, train_gt,  train_label = make_data(train)\n","dev_text, dev_gt, dev_label = make_data(dev)\n","test_text, test_gt, test_label = make_data(test)"],"metadata":{"id":"3qlPbyPxRc3h","executionInfo":{"status":"ok","timestamp":1680171702702,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# from keras.utils import pad_sequences\n","# from keras.utils import to_categorical\n","# from keras.preprocessing.text import Tokenizer\n","\n","# tokenizer = Tokenizer()\n","# tokenizer.fit_on_texts(train_text)\n","# vocab_size = len(tokenizer.word_index) + 1\n","\n","# def encoding(X, y):\n","#     # if not use_tokenizer:\n","#     #     X = X.astype(str)\n","#     X = tokenizer.texts_to_sequences(X)\n","#     X = pad_sequences(X, maxlen=max_len, padding='post')\n","#     y = np.asarray([np.asarray(row, dtype=float) for row in y], dtype=int)\n","#     return (X,y)"],"metadata":{"id":"O-_ZMBPUScT4","executionInfo":{"status":"ok","timestamp":1680171702702,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# from transformers import AutoTokenizer\n","# from keras.utils import pad_sequences\n","# import numpy as np\n","\n","# tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","\n","# def encoding(X, y):\n","#     X = [str(x) for x in X]\n","#     # X = pad_sequences(X, maxlen=max_len, padding='post')\n","#     X = np.array(tokenizer(X, max_length=max_len, padding='max_length', truncation=True)['input_ids'])\n","#     y = np.asarray([np.asarray(row, dtype=float) for row in y], dtype=int)\n","#     return (X,y)"],"metadata":{"id":"YzJ-rykX-urG","executionInfo":{"status":"ok","timestamp":1680171702702,"user_tz":-420,"elapsed":7,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# import pickle\n","\n","# # saving\n","# with open('drive/MyDrive/CODE/ViTHSD/model/tokenizer2.pickle', 'wb') as handle:\n","#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"ulcWGGxnSfmz","executionInfo":{"status":"ok","timestamp":1680171702702,"user_tz":-420,"elapsed":6,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# train_features = encoding(train_text, train_label)\n","# dev_features = encoding(dev_text, dev_label)\n","# test_features = encoding(test_text, test_label)"],"metadata":{"id":"3TnJyv3GSg_F","executionInfo":{"status":"ok","timestamp":1680171702703,"user_tz":-420,"elapsed":7,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# Model "],"metadata":{"id":"c5GcN3ydUd2F"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from keras.utils import pad_sequences\n","import numpy as np\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","\n","def encoding(X, y):\n","    X = [str(x) for x in X]\n","    X = {\n","        \"input_ids\": np.asarray(tokenizer(X, max_length=max_len, padding='max_length', truncation=True)['input_ids']),\n","        # \"token_type_ids\": np.asarray(tokenizer(X, max_length=max_len, padding='max_length', truncation=True)['token_type_ids']),\n","        \"attention_mask\": np.asarray(tokenizer(X, max_length=max_len, padding='max_length', truncation=True)['attention_mask'])\n","    }\n","    # X = tokenizer(X, max_length=max_len, padding='max_length', truncation=True)\n","    y = np.asarray([np.asarray(row, dtype=float) for row in y], dtype=int)\n","    return (X,y)"],"metadata":{"id":"uosCoSKmz4vM","executionInfo":{"status":"ok","timestamp":1680171708613,"user_tz":-420,"elapsed":5916,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["train_features = encoding(train_text, train_label)\n","dev_features = encoding(dev_text, dev_label)\n","test_features = encoding(test_text, test_label)"],"metadata":{"id":"blyGuXkFz56u","executionInfo":{"status":"ok","timestamp":1680171710793,"user_tz":-420,"elapsed":2185,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Build model"],"metadata":{"id":"iq0RswivjXzk"}},{"cell_type":"code","source":["# from transformers import AutoModel\n","\n","# model = AutoModel.from_pretrained(MODEL)\n","# embedding_matrix = model.embeddings.word_embeddings.weight.detach().numpy()\n","# # dim = model.embeddings.word_embeddings.embedding_dim\n","# # vocab = model.embeddings.word_embeddings.num_embeddings\n","# dim = embedding_matrix.shape[1]\n","# vocab = embedding_matrix.shape[0]"],"metadata":{"id":"rlBgcDWVUexv","executionInfo":{"status":"ok","timestamp":1680171710794,"user_tz":-420,"elapsed":10,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from transformers import TFAutoModel\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n","from tensorflow.keras.optimizers import Adam\n","\n","from keras.layers import Dense, Concatenate, Bidirectional, GRU, Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D, SpatialDropout1D, Dropout, concatenate\n","from keras.layers import Flatten, LSTM, Input, Reshape\n","\n","units = 112\n","NUM_LAYER = 4\n","filter_size = 5\n","\n","inputs = {\n","        'input_ids'     : Input((max_len,), dtype='int32', name='input_ids'), \n","        # 'token_type_ids': Input((max_len,), dtype='int32', name='token_type_ids'), \n","        'attention_mask': Input((max_len,), dtype='int32', name='attention_mask'),\n","}\n","pretrained_bert = TFAutoModel.from_pretrained(MODEL, output_hidden_states=True, from_pt=True)\n","hidden_states = pretrained_bert(inputs).hidden_states\n","\n","# pooled_output = concatenate(\n","#         tuple([hidden_states[i] for i in range(-4, 0)]), \n","#         name = 'last_4_hidden_states',\n","#         axis = -1\n","# )[:, 0, :]\n","pooled_output = concatenate(\n","        tuple([hidden_states[i] for i in range(-NUM_LAYER, 0)]), \n","        name = 'last_4_hidden_states',\n","        axis = -1\n",")\n","x = Dropout(0.2)(pooled_output)\n","\n","l1 = Bidirectional(GRU(units, return_sequences = True))(x)\n","l1 = Conv1D(filter_size, kernel_size = 5, padding = \"valid\", kernel_initializer = \"he_uniform\")(l1)\n","    \n","l2 = Bidirectional(LSTM(units, return_sequences = True))(x)\n","l2 = Conv1D(filter_size, kernel_size = 5, padding = \"valid\", kernel_initializer = \"he_uniform\")(l2)\n","    \n","avg_pool1 = GlobalAveragePooling1D()(l1)\n","max_pool1 = GlobalMaxPooling1D()(l1)\n","    \n","avg_pool2 = GlobalAveragePooling1D()(l2)\n","max_pool2 = GlobalMaxPooling1D()(l2)\n","    \n","    \n","x = Concatenate(axis=-1)([avg_pool1, max_pool1, avg_pool2, max_pool2])\n","\n","outputs = concatenate([\n","        Dense(units = 4, activation = 'softmax',name = \"target1\")(x),\n","        Dense(units = 4, activation = 'softmax',name = \"target2\")(x),\n","        Dense(units = 4, activation = 'softmax',name = \"target3\")(x),\n","        Dense(units = 4, activation = 'softmax',name = \"target4\")(x),\n","        Dense(units = 4, activation = 'softmax',name = \"target5\")(x)\n","], axis = -1)\n","\n","model = Model(inputs=inputs, outputs=outputs)\n","model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=\"binary_accuracy\")\n","\n","model.summary()"],"metadata":{"id":"fAPMbDtCemYB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680171730396,"user_tz":-420,"elapsed":19609,"user":{"displayName":"Sơn Lưu Thanh","userId":"09824077883060402796"}},"outputId":"4334b07a-0ac7-4ed3-e1f5-c64baccdc2c5"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," attention_mask (InputLayer)    [(None, 50)]         0           []                               \n","                                                                                                  \n"," input_ids (InputLayer)         [(None, 50)]         0           []                               \n","                                                                                                  \n"," tfxlm_roberta_model (TFXLMRobe  TFBaseModelOutputWi  278043648  ['attention_mask[0][0]',         \n"," rtaModel)                      thPoolingAndCrossAt               'input_ids[0][0]']              \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 50,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=(                                               \n","                                (None, 50, 768),                                                  \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768),                                                 \n","                                 (None, 50, 768)),                                                \n","                                 attentions=None, c                                               \n","                                ross_attentions=Non                                               \n","                                e)                                                                \n","                                                                                                  \n"," last_4_hidden_states (Concaten  (None, 50, 3072)    0           ['tfxlm_roberta_model[0][9]',    \n"," ate)                                                             'tfxlm_roberta_model[0][10]',   \n","                                                                  'tfxlm_roberta_model[0][11]',   \n","                                                                  'tfxlm_roberta_model[0][12]']   \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 50, 3072)     0           ['last_4_hidden_states[0][0]']   \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 50, 224)      2140992     ['dropout_37[0][0]']             \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, 50, 224)     2853760     ['dropout_37[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 46, 5)        5605        ['bidirectional[0][0]']          \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 46, 5)        5605        ['bidirectional_1[0][0]']        \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 5)           0           ['conv1d[0][0]']                 \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," global_max_pooling1d (GlobalMa  (None, 5)           0           ['conv1d[0][0]']                 \n"," xPooling1D)                                                                                      \n","                                                                                                  \n"," global_average_pooling1d_1 (Gl  (None, 5)           0           ['conv1d_1[0][0]']               \n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," global_max_pooling1d_1 (Global  (None, 5)           0           ['conv1d_1[0][0]']               \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 20)           0           ['global_average_pooling1d[0][0]'\n","                                                                 , 'global_max_pooling1d[0][0]',  \n","                                                                  'global_average_pooling1d_1[0][0\n","                                                                 ]',                              \n","                                                                  'global_max_pooling1d_1[0][0]'] \n","                                                                                                  \n"," target1 (Dense)                (None, 4)            84          ['concatenate[0][0]']            \n","                                                                                                  \n"," target2 (Dense)                (None, 4)            84          ['concatenate[0][0]']            \n","                                                                                                  \n"," target3 (Dense)                (None, 4)            84          ['concatenate[0][0]']            \n","                                                                                                  \n"," target4 (Dense)                (None, 4)            84          ['concatenate[0][0]']            \n","                                                                                                  \n"," target5 (Dense)                (None, 4)            84          ['concatenate[0][0]']            \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 20)           0           ['target1[0][0]',                \n","                                                                  'target2[0][0]',                \n","                                                                  'target3[0][0]',                \n","                                                                  'target4[0][0]',                \n","                                                                  'target5[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 283,050,030\n","Trainable params: 283,050,030\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n","\n","history = model.fit(train_features[0], train_features[1].reshape(-1, 20), \n","                    validation_data=(dev_features[0], dev_features[1].reshape(-1, 20)), \n","                    batch_size=64, epochs=30, verbose=True,\n","                    # callbacks=[early_stopping]\n","                )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYiQwfI8gt8P","outputId":"d0a56753-f0b4-4851-d5c2-2d8f27c573cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxlm_roberta_model/roberta/pooler/dense/kernel:0', 'tfxlm_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":[" 72/110 [==================>...........] - ETA: 32s - loss: 0.4036 - binary_accuracy: 0.8382"]}]},{"cell_type":"code","source":["y_pred = model.predict(test_features[0])"],"metadata":{"id":"4XWW25n-6lTi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"iRWsxbMXja8n"}},{"cell_type":"code","source":["import numpy as np\n","\n","pred = np.argmax(y_pred.reshape(-1, 5, 4), axis=-1)"],"metadata":{"id":"Y-h3Eks78Bwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Aspect + Polarity\\n\")\n","print(\"F1 = {}\".format(f1_score(pred, test_gt)))\n","print(\"Precision = {}\".format(precision_score(pred, test_gt)))\n","print(\"Recall = {}\".format(recall_score(pred, test_gt)))"],"metadata":{"id":"xZrpdt-68MIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Aspect only \n","\n","new_pred = []\n","new_y = []\n","\n","for k in pred:\n","    t = []\n","    for i in k:\n","        if i > 0:\n","            t.append(1)\n","        else:\n","            t.append(i)\n","    new_pred.append(t)\n","\n","for k in test_gt:\n","    t = []\n","    for i in k:\n","        if i > 0:\n","            t.append(1)\n","        else:\n","            t.append(i)\n","    new_y.append(t)"],"metadata":{"id":"U8Y7lCa-mhrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Aspect\\n\")\n","print(\"F1 = {}\".format(f1_score(new_pred, new_y)))\n","print(\"Precision = {}\".format(precision_score(new_pred, new_y)))\n","print(\"Recall = {}\".format(recall_score(new_pred, new_y)))"],"metadata":{"id":"2DXoaEdhncLQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.save(\"drive/MyDrive/CODE/ViTHSD/model/{}.h5\".format(MODEL))\n","model.save(\"drive/MyDrive/CODE/ViTHSD/model/bigrulstmcnn_xlmr.h5\".format(MODEL))"],"metadata":{"id":"LZuTGsda6bWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from sklearn.metrics import classification_report\n","# tg = 4\n","# print(classification_report(pred[:,tg], test_gt[:,tg]))"],"metadata":{"id":"67ubOmgrHGgV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Results"],"metadata":{"id":"aux-DZFyu4Pn"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_metric(history, metric):\n","    train_metrics = history.history[metric]\n","    val_metrics = history.history['val_'+metric]\n","    epochs = range(1, len(train_metrics) + 1)\n","    plt.plot(epochs, train_metrics)\n","    plt.plot(epochs, val_metrics)\n","    plt.title('Training and validation '+ metric)\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(metric)\n","    plt.legend([\"train_\"+metric, 'val_'+metric])\n","    plt.show()"],"metadata":{"id":"0dZC05EpuMx4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_metric(history, 'loss')"],"metadata":{"id":"UVtcBZv7uNdm"},"execution_count":null,"outputs":[]}]}